{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mental Health Text Analysis Pipeline\n",
    "\n",
    "This notebook processes mental health-related text data using NLP techniques and API services.\n",
    "It includes a pilot test section to validate the pipeline on a small subset before processing the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment Variables for API Keys\n",
    "\n",
    "We'll load API keys from environment variables to keep them secure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys (loaded from environment variables)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Add any other API keys as needed\n",
    "# OTHER_API_KEY = os.getenv(\"OTHER_API_KEY\")\n",
    "\n",
    "# Validate API keys\n",
    "def validate_api_keys():\n",
    "    \"\"\"Validate that required API keys are available.\"\"\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        logger.warning(\"OpenAI API key not found in environment variables.\")\n",
    "        print(\"‚ö†Ô∏è Warning: OpenAI API key not found in environment variables.\")\n",
    "        # You can decide whether to raise an exception or continue with limited functionality\n",
    "    else:\n",
    "        print(\"‚úÖ OpenAI API key loaded successfully.\")\n",
    "    \n",
    "    # Add validation for other API keys as needed\n",
    "\n",
    "validate_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the configuration for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created results directory: full_results\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data/mentalhealth_post_features_tfidf_256.csv\"\n",
    "RESULTS_DIR = \"full_results\"\n",
    "PILOT_SAMPLE_SIZE = 5\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)\n",
    "    print(f\"Created results directory: {RESULTS_DIR}\")\n",
    "else:\n",
    "    print(f\"Results directory already exists: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the data from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data/mentalhealth_post_features_tfidf_256.csv\n",
      "Loaded 13514 records\n",
      "\n",
      "Dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>post</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>flesch_kincaid_grade_level</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_wish</th>\n",
       "      <th>tfidf_without</th>\n",
       "      <th>tfidf_wonder</th>\n",
       "      <th>tfidf_work</th>\n",
       "      <th>tfidf_worri</th>\n",
       "      <th>tfidf_wors</th>\n",
       "      <th>tfidf_would</th>\n",
       "      <th>tfidf_wrong</th>\n",
       "      <th>tfidf_x200b</th>\n",
       "      <th>tfidf_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Autumfire117</td>\n",
       "      <td>2020/01/01</td>\n",
       "      <td>Not depressed or suicidal, yet the thought of ...</td>\n",
       "      <td>6.283511</td>\n",
       "      <td>5.687673</td>\n",
       "      <td>6.568202</td>\n",
       "      <td>80.795116</td>\n",
       "      <td>66.002584</td>\n",
       "      <td>9.955408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>elf_boy_</td>\n",
       "      <td>2020/01/01</td>\n",
       "      <td>How I Barely Survived the Last Decade Trigger ...</td>\n",
       "      <td>4.953877</td>\n",
       "      <td>6.139650</td>\n",
       "      <td>5.820522</td>\n",
       "      <td>78.808202</td>\n",
       "      <td>69.141398</td>\n",
       "      <td>9.052063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.096198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>mcks02</td>\n",
       "      <td>2020/01/01</td>\n",
       "      <td>Coping skills I was wondering if anyone had an...</td>\n",
       "      <td>0.919777</td>\n",
       "      <td>2.657734</td>\n",
       "      <td>3.307321</td>\n",
       "      <td>90.400864</td>\n",
       "      <td>80.951220</td>\n",
       "      <td>6.229480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137643</td>\n",
       "      <td>0.092402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>IAndrOwS</td>\n",
       "      <td>2020/01/01</td>\n",
       "      <td>Overcoming a Mental Illness is Like Trying to ...</td>\n",
       "      <td>1.398685</td>\n",
       "      <td>4.035708</td>\n",
       "      <td>2.814915</td>\n",
       "      <td>88.778398</td>\n",
       "      <td>87.263069</td>\n",
       "      <td>5.481930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062912</td>\n",
       "      <td>0.087707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Nyteblk</td>\n",
       "      <td>2020/01/01</td>\n",
       "      <td>Sooo I need your help I‚Äôm going to lead with w...</td>\n",
       "      <td>5.030568</td>\n",
       "      <td>5.675974</td>\n",
       "      <td>6.477938</td>\n",
       "      <td>76.127234</td>\n",
       "      <td>68.640288</td>\n",
       "      <td>9.055476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit        author        date  \\\n",
       "0  mentalhealth  Autumfire117  2020/01/01   \n",
       "1  mentalhealth      elf_boy_  2020/01/01   \n",
       "2  mentalhealth        mcks02  2020/01/01   \n",
       "3  mentalhealth      IAndrOwS  2020/01/01   \n",
       "4  mentalhealth       Nyteblk  2020/01/01   \n",
       "\n",
       "                                                post  \\\n",
       "0  Not depressed or suicidal, yet the thought of ...   \n",
       "1  How I Barely Survived the Last Decade Trigger ...   \n",
       "2  Coping skills I was wondering if anyone had an...   \n",
       "3  Overcoming a Mental Illness is Like Trying to ...   \n",
       "4  Sooo I need your help I‚Äôm going to lead with w...   \n",
       "\n",
       "   automated_readability_index  coleman_liau_index  \\\n",
       "0                     6.283511            5.687673   \n",
       "1                     4.953877            6.139650   \n",
       "2                     0.919777            2.657734   \n",
       "3                     1.398685            4.035708   \n",
       "4                     5.030568            5.675974   \n",
       "\n",
       "   flesch_kincaid_grade_level  flesch_reading_ease  gulpease_index  \\\n",
       "0                    6.568202            80.795116       66.002584   \n",
       "1                    5.820522            78.808202       69.141398   \n",
       "2                    3.307321            90.400864       80.951220   \n",
       "3                    2.814915            88.778398       87.263069   \n",
       "4                    6.477938            76.127234       68.640288   \n",
       "\n",
       "   gunning_fog_index  ...  tfidf_wish  tfidf_without  tfidf_wonder  \\\n",
       "0           9.955408  ...         0.0       0.139581      0.000000   \n",
       "1           9.052063  ...         0.0       0.000000      0.000000   \n",
       "2           6.229480  ...         0.0       0.000000      0.137643   \n",
       "3           5.481930  ...         0.0       0.000000      0.000000   \n",
       "4           9.055476  ...         0.0       0.000000      0.000000   \n",
       "\n",
       "   tfidf_work  tfidf_worri  tfidf_wors  tfidf_would  tfidf_wrong  tfidf_x200b  \\\n",
       "0    0.000000          0.0    0.000000     0.051431     0.000000          0.0   \n",
       "1    0.000000          0.0    0.000000     0.020834     0.096198          0.0   \n",
       "2    0.092402          0.0    0.000000     0.000000     0.000000          0.0   \n",
       "3    0.179770          0.0    0.062912     0.087707     0.000000          0.0   \n",
       "4    0.000000          0.0    0.000000     0.000000     0.258315          0.0   \n",
       "\n",
       "   tfidf_year  \n",
       "0    0.093246  \n",
       "1    0.245525  \n",
       "2    0.081734  \n",
       "3    0.079508  \n",
       "4    0.152145  \n",
       "\n",
       "[5 rows x 350 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(data_path=DATA_PATH):\n",
    "    \"\"\"Load data from CSV file.\"\"\"\n",
    "    print(f\"Loading data from {data_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        print(f\"Loaded {len(df)} records\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load the data\n",
    "df = load_data()\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(\"\\nDataset preview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Preprocess the data before analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the data.\"\"\"\n",
    "    print(\"Preprocessing data...\")\n",
    "    \n",
    "    # Add your preprocessing steps here\n",
    "    # Example: df = df.dropna(subset=['text'])\n",
    "    \n",
    "    print(\"Preprocessing complete.\")\n",
    "    return df\n",
    "\n",
    "# We'll apply preprocessing in the pilot and full run sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis Function\n",
    "\n",
    "Define the function to analyze a single text entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    \"\"\"Analyze a single text entry.\"\"\"\n",
    "    \n",
    "    result = {\n",
    "        \"sentiment\": None,\n",
    "        \"topics\": [],\n",
    "        \"mental_health_indicators\": [],\n",
    "        \"risk_assessment\": None,\n",
    "    }\n",
    "    \n",
    "    if OPENAI_API_KEY:\n",
    "        # TODO: replace with actual API calls\n",
    "        # result[\"sentiment\"] = call_openai_api(text)\n",
    "        pass\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing Function\n",
    "\n",
    "Define the function to process a batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(df):\n",
    "    \"\"\"Process a batch of data.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Extract text from row - adjust column name as needed\n",
    "        # Assuming there's a 'text' column - modify as needed\n",
    "        text = row.get('text', '')\n",
    "        \n",
    "        # Skip empty text\n",
    "        if not text:\n",
    "            continue\n",
    "            \n",
    "        # Process the text\n",
    "        result = analyze_text(text)\n",
    "        \n",
    "        # Add metadata\n",
    "        result['id'] = row.get('id', idx)\n",
    "        \n",
    "        # Add to results\n",
    "        results.append(result)\n",
    "        \n",
    "        # Log progress periodically\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"Processed {idx + 1} records\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results Function\n",
    "\n",
    "Define the function to save results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, filename=\"results.csv\"):\n",
    "    \"\"\"Save results to a CSV file.\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to save\")\n",
    "        return\n",
    "        \n",
    "    output_path = os.path.join(RESULTS_DIR, filename)\n",
    "    print(f\"Saving results to {output_path}\")\n",
    "    \n",
    "    # Get all possible keys from all dictionaries\n",
    "    all_keys = set()\n",
    "    for result in results:\n",
    "        all_keys.update(result.keys())\n",
    "    \n",
    "    with open(output_path, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=list(all_keys))\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "        \n",
    "    print(f\"Saved {len(results)} records to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot Test\n",
    "\n",
    "Run a pilot test on a small sample of the data to validate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pilot():\n",
    "    \"\"\"Run a pilot test on a small sample of the data.\"\"\"\n",
    "    print(f\"\\nüß™ Running pilot test on {PILOT_SAMPLE_SIZE} records\")\n",
    "    \n",
    "    # Take a small sample\n",
    "    sample_df = df.head(PILOT_SAMPLE_SIZE)\n",
    "    \n",
    "    # Preprocess\n",
    "    sample_df = preprocess_data(sample_df)\n",
    "    \n",
    "    # Process the sample\n",
    "    results = process_batch(sample_df)\n",
    "    \n",
    "    # Save pilot results\n",
    "    save_results(results, \"pilot_results.csv\")\n",
    "    \n",
    "    # Print sample of results for inspection\n",
    "    print(\"\\nPilot test results sample:\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i+1}: {result}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the pilot test\n",
    "pilot_results = run_pilot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pipeline\n",
    "\n",
    "Run the full pipeline on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline():\n",
    "    \"\"\"Run the full pipeline on all data.\"\"\"\n",
    "    print(\"\\nüöÄ Running full pipeline\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Preprocess\n",
    "    processed_df = preprocess_data(df)\n",
    "    \n",
    "    # Process all data\n",
    "    results = process_batch(processed_df)\n",
    "    \n",
    "    # Save results\n",
    "    save_results(results)\n",
    "    \n",
    "    # Calculate and log total runtime\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Full pipeline completed with {len(results)} results\")\n",
    "    print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment the following line to run the full pipeline\n",
    "# full_results = run_full_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a pipeline for analyzing mental health text data. It includes:\n",
    "\n",
    "1. Loading API keys from environment variables\n",
    "2. Using the mentalhealth_post_features_tfidf_256.csv file (configurable)\n",
    "3. A pilot test on 5 examples to validate the pipeline structure\n",
    "4. The full pipeline for processing the entire dataset\n",
    "\n",
    "To use a different dataset, simply change the DATA_PATH variable at the beginning of the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
